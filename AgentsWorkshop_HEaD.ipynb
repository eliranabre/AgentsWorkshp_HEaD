{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e064575-cb25-42cf-96cd-15f264bbea25",
   "metadata": {},
   "source": [
    "## 📌 Agenda\n",
    "\n",
    "1. **Setups**  \n",
    "2. **Models** → Talk directly with the model  \n",
    "3. **Graphs** → Learn graph structure through mini examples *(Graph I–V)*\n",
    "4. **LangGraph concepts** → human in the loop (HITL) and time travel\n",
    "5. **ChatBot** → Build a practical chatbot enriched with tools  \n",
    "6. **Podcast Generator** → Use search to gather information, apply planning & critique, and generate a podcast on your chosen subject  \n",
    "\n",
    "\n",
    "\n",
    "### 🚀 Let’s get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74959cba-3059-4843-80f4-cea2b2eca127",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1607c59-757d-40ce-a5b4-cf89c3ab8d97",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebad417-7934-4e92-8e2e-dd1baf735bd0",
   "metadata": {},
   "source": [
    "## ▶️ Using Jupyter Notebooks\n",
    "\n",
    "- Press **`Ctrl+Enter`** to run the selected cell.  \n",
    "- Alternatively, hover over a code cell and click the **▶️ play button** on the right.  \n",
    "- Each code cell shows an execution counter on the left:  \n",
    "  - `In [ ]:` → the cell has **not run yet**  \n",
    "  - `In [5]:` → the cell has **already run** (5th in order)  \n",
    "  - `In [*]:` → the cell is **currently running**  \n",
    "- When code is running, you’ll also see a **sand-watch (⏳)** or “busy” indicator in the notebook tab or toolbar.  \n",
    "\n",
    "- To make it interactive, every time you see **`None`** you are expected to replace it with the required values.  \n",
    "  If you’re not sure, don’t worry . every exercise has an **Answer Key** that is hidden in a collapsible block.  \n",
    "  Click **“Answer key (click to expand)”** under the code snippet to reveal the solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38658062-f3cc-43c4-98bf-7a3f32255ea5",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5185267-f703-4c95-a6bb-308506a1efcb",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4b478-98a9-4056-a9cb-4e00769e7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r https://raw.githubusercontent.com/eliranabre/AgentsWorkshp_HEaD/main/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cbe080-6e8b-4e98-a758-6adc5fd185d3",
   "metadata": {},
   "source": [
    "## ⚙️ LLM Setup\n",
    "\n",
    "This section configures all the API keys, endpoints, and deployment names as environment variables.\n",
    "These settings allow our LangGraph agents to securely access all the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa96c0-aae7-44f4-86f4-ff33aea5859e",
   "metadata": {},
   "source": [
    "First, let’s initialize our connection to the Azure OpenAI endpoint using environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b71aa69-14ce-428b-8722-bfa5f7423436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.environ[\"OPENAI_DEPLOYMENT_NAME\"],  \n",
    "    openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"OPENAI_API_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c44c92-f37a-4643-82f7-2b8d09b9ce1f",
   "metadata": {},
   "source": [
    "Now we can test our model by calling it with a simple prompt.   \n",
    "Enter a question you would like to ask the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f09c0-d9cb-4d98-9ef2-d9e5b1057e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"None\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ccd89-359e-4bdf-874b-71f50bbfa5c3",
   "metadata": {},
   "source": [
    "The response we receive from the model includes both the **actual content** (the model’s answer) and **extra metadata** (such as token usage, request IDs, and safety checks).  \n",
    "👉 If you only want the explicit answer, use the **`content`** field of the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbaa59d-023d-43e0-9806-76c4e48b067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228988e-57c9-4de2-ac48-56938844dc33",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5da76a-af00-4222-b1b0-b866afe4591e",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78a89b-0ff1-474d-99fc-f02cafa1d7c1",
   "metadata": {},
   "source": [
    "## 🖼️ Image Generation\n",
    "\n",
    "Now that we’ve set up our LLM, it’s time to configure **image generation**.  \n",
    "In this notebook, we’ll be using **OpenAI’s DALL·E 3** through the Azure OpenAI service.  \n",
    "\n",
    "We’ll create a helper function that takes a **text prompt** and generates an image using the **DALL·E model**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31205eb6-a98b-4978-a0c8-774ed1f55319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "def create_image(prompt: str) -> str:\n",
    "    client = AzureOpenAI(\n",
    "        api_version=os.getenv(\"DALLE_API_VERSION\"),\n",
    "        azure_endpoint=os.getenv(\"DALLE_API_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"DALLE_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    result = client.images.generate(\n",
    "        model=os.getenv(\"DALLE_DEPLOYMENT_NAME\"), prompt=prompt, n=1\n",
    "    )\n",
    "\n",
    "    image_url = json.loads(result.model_dump_json())[\"data\"][0][\"url\"]\n",
    "\n",
    "    return image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab551b-4e9c-45a6-8ebc-4be406b2efb1",
   "metadata": {},
   "source": [
    "Fill in the prompt with the description of the image you want to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61a2a7f-a543-4d01-9cc5-95cd845866a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"None\"\n",
    "\n",
    "image_url = create_image(prompt)\n",
    "\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8398d167-909a-4c8d-b777-4e04d1f8af26",
   "metadata": {},
   "source": [
    "## 🕸️ Graphs\n",
    "\n",
    "In this section, we’ll explore the fundamentals of **LangGraph** by building small, hands-on examples.  \n",
    "You’ll learn how **nodes**, **edges**, **state**, and **execution paths** work together to form a graph.  \n",
    "\n",
    "These simple graphs will help you build the intuition needed before moving on to more advanced agent workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c51e3-a453-43b2-a610-bcf0cf6b6532",
   "metadata": {},
   "source": [
    "##### **Graph 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd80f4-1e64-4549-bd23-c88551fd52c8",
   "metadata": {},
   "source": [
    "We’re building a very simple LangGraph state graph that consists of a single node. This graph takes a user’s name, passes it through the greeter node, and outputs a friendly greeting message. It’s a minimal example to demonstrate how state flows through a LangGraph application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9a6c424e-e138-4aa4-935b-b0ce088b97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "import random\n",
    "from typing import Dict, List, TypedDict\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957cd20d-fa1c-4cf8-b45c-0687d7805756",
   "metadata": {},
   "source": [
    "Lets Define the state schema. \n",
    "A state schema in LangGraph defines the structure and types of the data shared between nodes as the graph runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f13b5d52-26dd-430c-8bb8-4f88519417c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, the state has only one key: message. a string that will be modified as it moves through nodes.\n",
    "\n",
    "class WorkflowState(TypedDict): # Our state schema\n",
    "    message : str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110d238-eeec-4638-a5f8-6896150e8832",
   "metadata": {},
   "source": [
    "Node logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f02d8134-2e63-4834-8a78-95f78a8158f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting_node(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Simple node that adds a greeting message to the state\"\"\"\n",
    "\n",
    "    state[\"message\"] = f\"Hello {state['message']}, how are you?\"\n",
    "\n",
    "    # Returns the updated state to be passed along in the graph.\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd7df1-068b-47c4-8ebc-6fdfb54f1c12",
   "metadata": {},
   "source": [
    "Build the graph (insert in the ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f90ea0-1a2b-40a9-af36-087410c38c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new state graph with our schema.\n",
    "# Replace None with the state schema class we defined above\n",
    "graph = StateGraph(None) \n",
    "\n",
    "# Add the greeter node.\n",
    "# First \"None\" → choose the the node's name as a string \n",
    "# Second None → the function that should run in the node\n",
    "graph.add_node(\"None\", None) \n",
    "\n",
    "# Define the entry point.\n",
    "# Replace None with the name of the node that should run first\n",
    "graph.set_entry_point(\"None\") \n",
    "\n",
    "# Define the finish point.\n",
    "# Replace None with the name of the node that should end the flow \n",
    "graph.set_finish_point(\"None\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc96ce-74cc-4c67-830b-8eff9693cf8e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "# Creates a new state graph with our schema.\n",
    "# Replace None with the state schema class we defined above\n",
    "graph = StateGraph(WorkflowState) \n",
    "\n",
    "# Add the greeter node.\n",
    "# First \"None\" → choose the node's name as a string \n",
    "# Second None → the function that should run in the node\n",
    "graph.add_node(\"greeter\", greeting_node) \n",
    "\n",
    "# Define the entry point.\n",
    "# Replace None with the name of the node that should run first\n",
    "graph.set_entry_point(\"greeter\") \n",
    "\n",
    "# Define the finish point.\n",
    "# Replace None with the name of the node that should end the flow \n",
    "graph.set_finish_point(\"greeter\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275190f-cf0e-4fd6-9102-9b8730f1324b",
   "metadata": {},
   "source": [
    "##### **compile()**\n",
    "Compiling is a pretty simple step. It provides a few basic checks on the structure of your graph (no orphaned nodes, etc).  \n",
    "It is also where you can specify runtime args like checkpointer. You compile your graph by just calling the .compile()  \n",
    "You MUST compile your graph before you can use it.  \n",
    "\n",
    "Lets compile the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8d1aa957-9e00-4705-a95b-3783e3502fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc876c-7b42-4362-9547-b81be221d587",
   "metadata": {},
   "source": [
    "Now lets see how the graph looks like:  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2a38d00-ed68-4e7c-b484-46baae65333e",
   "metadata": {},
   "source": [
    "![Conditional Graph](https://raw.githubusercontent.com/eliranabre/AgentsWorkshp_HEaD/main/oneNodeGraph.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e8f783-6427-4d51-8380-b1f30267a37e",
   "metadata": {},
   "source": [
    "run the graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a7166-2314-4832-bbe3-71f6af16eed2",
   "metadata": {},
   "source": [
    "👉 Insert your name instead of **`None`** in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2e3b58fc-b345-41db-bd9b-279fa02960ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\"message\": \"None\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774395d7-7d22-40fd-8c7a-3ea3588e7e1d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "# Example: Replace None with your name as a string\n",
    "result = app.invoke({\"message\": \"Eliran\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fdcd41-980a-417d-ad0f-47c4136d873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get(\"message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d5886-3fd6-473e-ad17-a8f8d94f7161",
   "metadata": {},
   "source": [
    "##### **Graph 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6271aa-d445-4794-9f9a-d0897804de3e",
   "metadata": {},
   "source": [
    "This graph is a simple two-step sequential workflow.  \n",
    "It first greets a person by name, then appends their age to the message, producing a final combined string.  \n",
    "This demonstrates how state flows through multiple nodes, with each node building on the output of the previous one.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c61aa578-7b28-4c2d-9e22-ddc6767b765b",
   "metadata": {},
   "source": [
    "![Conditional Graph](https://raw.githubusercontent.com/eliranabre/AgentsWorkshp_HEaD/main/multi.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b2a310ab-e60a-469c-8ac5-a01f5e547eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowState(TypedDict):\n",
    "    name: str\n",
    "    age: int\n",
    "    final: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8d8f99a2-fc85-4c58-929b-b3e9a7410fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First node: greeting\n",
    "def first_node(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Greets the user by name.\"\"\"\n",
    "    # Replace None with the correct string template\n",
    "    state[\"final\"] = f\"Hi {state[None]}!\"   # Hint: use the state's name\n",
    "    return state\n",
    "\n",
    "# Second node: append age\n",
    "def second_node(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Appends the user's age to the message.\"\"\"\n",
    "    # Replace None with the correct keys\n",
    "    state[\"final\"] = f\"{state[None]} You are {state[None]} years old!\"  \n",
    "    return state\n",
    "\n",
    "# Third node: farewell\n",
    "def farewell_node(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Adds a farewell message.\"\"\"\n",
    "    # Replace None with the right key\n",
    "    state[\"final\"] = f\"{state[None]} Have a great day!\"  \n",
    "    # Hint: continue from the existing final message\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f114f5b-c703-470f-9fee-c038df6f8405",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "# First node: greeting\n",
    "def first_node(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Greets the user by name.\"\"\"\n",
    "    state[\"final\"] = f\"Hi {state['name']}!\"\n",
    "    return state\n",
    "\n",
    "# Second node: append age\n",
    "def second_node(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Appends the user's age to the message.\"\"\"\n",
    "    state[\"final\"] = f\"{state['final']} You are {state['age']} years old!\"\n",
    "    return state\n",
    "\n",
    "# Third node: farewell\n",
    "def farewell_node(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Adds a farewell message.\"\"\"\n",
    "    state[\"final\"] = f\"{state['final']} Have a great day!\"\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "787a1e94-c86f-48f2-8007-6284bc5c87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "graph = StateGraph(WorkflowState)\n",
    "\n",
    "# Add the nodes\n",
    "# First \"None\" → name of the node (string)\n",
    "# Second None → the function that should run in that node\n",
    "graph.add_node(\"None\", None)  \n",
    "graph.add_node(\"None\", None)  \n",
    "graph.add_node(\"None\", None)  \n",
    "\n",
    "# Define entry point\n",
    "# Replace None with the name of the first node\n",
    "graph.set_entry_point(\"None\")  \n",
    "\n",
    "# Add edges between nodes\n",
    "# Replace both \"None\" values with the correct source and destination node names\n",
    "graph.add_edge(\"None\", \"None\")   # sequential flow\n",
    "graph.add_edge(\"None\", \"None\")  \n",
    "\n",
    "# Define finish point\n",
    "# Replace None with the name of the last node\n",
    "graph.set_finish_point(\"None\")  \n",
    "\n",
    "# Compile the app\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d670c85-0566-4d32-bbe7-c4c4651ec5a9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "# Build the graph\n",
    "graph = StateGraph(WorkflowState)\n",
    "\n",
    "# Add the nodes\n",
    "graph.add_node(\"first_node\", first_node)  \n",
    "graph.add_node(\"second_node\", second_node)  \n",
    "graph.add_node(\"farewell_node\", farewell_node)  \n",
    "\n",
    "# Define entry point\n",
    "graph.set_entry_point(\"first_node\")  \n",
    "\n",
    "# Add edges between nodes\n",
    "graph.add_edge(\"first_node\", \"second_node\")   # sequential flow\n",
    "graph.add_edge(\"second_node\", \"farewell_node\")  \n",
    "\n",
    "# Define finish point\n",
    "graph.set_finish_point(\"farewell_node\")  \n",
    "\n",
    "# Compile the app\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b989163-c518-4317-a05c-7dbf9d0aa3a3",
   "metadata": {},
   "source": [
    "👉 Insert a name and age instead of None in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db24f48-9075-46f9-9e22-7fd6f7046603",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\"name\": \"None\", \"age\": None})\n",
    "print(result.get(\"final\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1fc5f-3d47-4e46-b6f1-669fc3fe70b1",
   "metadata": {},
   "source": [
    "##### **Graph 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1914e6-41d8-4d50-899d-1bf74a77196e",
   "metadata": {},
   "source": [
    "This graph demonstrates **conditional routing** in LangGraph.  \n",
    "Instead of following a fixed sequence of nodes, the flow dynamically chooses between two calculation nodes: addition or subtraction based on the `operation` field in the state.  \n",
    "\n",
    "It’s a minimal example of **branching logic** in a state graph.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6af93b7-4720-4fb2-b9fa-e2b3d301b8e2",
   "metadata": {},
   "source": [
    "![Conditional Graph](https://raw.githubusercontent.com/eliranabre/AgentsWorkshp_HEaD/main/conditional.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9007094a-5f49-45fa-ac0d-0cfe84d7d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workflow state\n",
    "class WorkflowState(TypedDict):\n",
    "    number1: None        # Hint: should hold the first number\n",
    "    operation: None      # Hint: should hold the operation symbol (\"+\" or \"-\")\n",
    "    number2: None        # Hint: should hold the second number\n",
    "    finalNumber: None    # Hint: should hold the result after calculation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ba1bc-c562-4cb8-be65-7bb3413e711d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "# Define the workflow state\n",
    "class WorkflowState(TypedDict):\n",
    "    number1: int        # first number\n",
    "    operation: str      # operation symbol (\"+\" or \"-\")\n",
    "    number2: int        # second number\n",
    "    finalNumber: int    # result after calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ac336329-579b-4a3e-9f48-2dff1f6cd688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adder(state:WorkflowState) -> WorkflowState:\n",
    "    \"\"\"This node adds the 2 numbers\"\"\"\n",
    "    state[\"finalNumber\"] = state[\"number1\"] + state[\"number2\"]\n",
    "\n",
    "    return state\n",
    "\n",
    "def subtractor(state:WorkflowState) -> WorkflowState:\n",
    "    \"\"\"This node subtracts the 2 numbers\"\"\"\n",
    "    state[\"finalNumber\"] = state[\"number1\"] - state[\"number2\"]\n",
    "    return state\n",
    "\n",
    "#router function that doesn’t change the state. it returns the name of the conditional edge to follow next.\n",
    "def decide_next_node(state:WorkflowState) -> WorkflowState:\n",
    "    \"\"\"This node will select the next node of the graph\"\"\"\n",
    "\n",
    "    if state[\"operation\"] == \"+\":\n",
    "        return \"addition_operation\"\n",
    "\n",
    "    elif state[\"operation\"] == \"-\":\n",
    "        return \"subtraction_operation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "df19839b-1e3b-4f6b-85d9-15fb3b625cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(WorkflowState)\n",
    "\n",
    "graph.add_node(\"add_node\", adder)\n",
    "graph.add_node(\"subtract_node\", subtractor)\n",
    "graph.add_node(\"router\", lambda state:state) # passthrough function\n",
    "\n",
    "graph.add_edge(START, \"router\")\n",
    "\n",
    "# Defines dynamic branching from the router node\n",
    "graph.add_conditional_edges(\n",
    "    \"router\", # Source node\n",
    "    decide_next_node, # picks which mapping key to follow\n",
    "\n",
    "    {\n",
    "        # Edge: Node => Mapping values are the actual node names to execute next\n",
    "        # Replace None with the correct node name\n",
    "        \"addition_operation\": \"None\",\n",
    "        \"subtraction_operation\": \"None\"\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "graph.add_edge(\"add_node\", END)\n",
    "graph.add_edge(\"subtract_node\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56237993-3ddf-4fe9-9366-975fff1e54f3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "# Defines dynamic branching from the router node\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",          # Source node\n",
    "    decide_next_node,  # picks which mapping key to follow\n",
    "\n",
    "    {\n",
    "        \"addition_operation\": \"add_node\",        # goes to the addition node\n",
    "        \"subtraction_operation\": \"subtract_node\" # goes to the subtraction node\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5365ddc-3f9f-492b-9e31-509ae4f140fa",
   "metadata": {},
   "source": [
    "👉 Replace each None with two numbers of your choice and an operation symbol (+ or -)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc25c4-25a5-4a87-b90f-835a02822ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\"number1\": None, \"operation\": \"None\", \"number2\": None})\n",
    "print(result.get(\"finalNumber\", \"no result\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d8537-9ad2-48a2-b684-3df1cbacf613",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "# Example: add 5 + 3\n",
    "result = app.invoke({\"number1\": 5, \"operation\": \"+\", \"number2\": 3})\n",
    "print(result.get(\"finalNumber\", \"no result\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393791e-d5fc-43c3-80a2-3d1ab3f4aac4",
   "metadata": {},
   "source": [
    "##### Graph 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbfd04-5688-4334-8175-15cb071b61e0",
   "metadata": {},
   "source": [
    "This graph demonstrates **looping** in LangGraph.  \n",
    "It repeatedly generates random numbers until a stopping condition is met,  \n",
    "illustrating how **conditional edges** can be used to create iterative flows within a state graph.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59d7280-d65a-4e87-83c5-ac66caea16a0",
   "metadata": {},
   "source": [
    "![Conditional Graph](https://raw.githubusercontent.com/eliranabre/AgentsWorkshp_HEaD/main/loop.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "867f845e-f0a7-4ed0-8bf2-823edd770187",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowState(TypedDict):\n",
    "    name: str\n",
    "    numbersHistory: List[int]\n",
    "    counter: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "36a55e93-da2b-422a-b5a5-7c9fb55a77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting_node(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Greeting Node which says hi to the person\"\"\"\n",
    "    state[\"name\"] = f\"Hi there, {state['name']}\"\n",
    "    state[\"counter\"] = 0\n",
    "\n",
    "    return state\n",
    "\n",
    "def random_node(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Generates a random number from 0 to 10\"\"\"\n",
    "    state[\"numbersHistory\"].append(random.randint(0, 10))\n",
    "    state[\"counter\"] += 1\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def should_continue(state: WorkflowState) -> str:\n",
    "    \"\"\"Function to decide what to do next\"\"\"\n",
    "    if state[\"counter\"] < 5:\n",
    "        print(\"ENTERING LOOP\", state[\"counter\"])\n",
    "        return \"loop\"  # Continue looping\n",
    "    else:\n",
    "        return \"exit\"  # Exit the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "42ae4378-08da-48d7-8209-dc4d7d597944",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(WorkflowState)\n",
    "\n",
    "graph.add_node(\"greeting\", greeting_node)\n",
    "graph.add_node(\"random\", random_node)\n",
    "\n",
    "graph.set_entry_point(\"greeting\")\n",
    "graph.add_edge(\"greeting\", \"random\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"random\",     # Source node\n",
    "    should_continue, # Action\n",
    "    {\n",
    "        \"loop\": \"random\", # loops back to random when \"loop\" is returned\n",
    "        \"exit\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87338d99-787c-4884-8d69-836628519dc5",
   "metadata": {},
   "source": [
    "👉 Insert a name instead of None in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a1f73d-84d1-4f24-abd8-629c2a2a8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"name\":\"None\", \"numbersHistory\":[], \"counter\":-100})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52aec50-0b43-49bd-b496-6b5b19b71c2e",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2bd9df-c683-4de8-8dd5-031f9097a8b7",
   "metadata": {},
   "source": [
    "## 👤 Human-in-the-Loop\n",
    "\n",
    "To **review, edit, and approve** tool calls in an agent or workflow, LangGraph supports **interrupts** - special pause points where execution stops and waits for human input.  \n",
    "\n",
    "- **Interrupts (dynamic breakpoints):**  \n",
    "  Triggered based on the current state of the graph.  \n",
    "  You can call `interrupt(...)` in a node to pause execution.  \n",
    "  The graph then resumes with the user’s input.  \n",
    "\n",
    "💡 This is useful for tasks like approvals, edits, or gathering extra context.  \n",
    "\n",
    "\n",
    "#### What we’re about to build\n",
    "\n",
    "**Flow:** `draft → review (pause with interrupt) → finalize`\n",
    "\n",
    "1. The model writes a short draft.  \n",
    "2. The graph **pauses** and asks the user to approve or edit.  \n",
    "3. If approved → return the draft.  \n",
    "4. If edited → revise via the model, then return.  \n",
    "\n",
    "This is the **core pattern** behind approvals, edits, and human checkpoints in agentic systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8b92d122-a0b8-40c0-8a03-2c9743d9c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- imports ---\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bdd74814-8886-4c0b-ab45-d435d332b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- graph state ---\n",
    "class State(TypedDict, total=False):\n",
    "    subject: str\n",
    "    draft: str\n",
    "    final: str\n",
    "    human_feedback: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a97036-3d01-40a2-962b-6b2c75d3146e",
   "metadata": {},
   "source": [
    "Lets define the graph nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2c9fa8b1-c5e7-4f30-8634-1da5006b97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- draft node ---\n",
    "def draft_node(state: State) -> State:\n",
    "    subject = (state.get(\"subject\") or \"\").strip()\n",
    "    if not subject:\n",
    "        return {\"draft\": \"⚠️ No subject provided.\"}\n",
    "\n",
    "    sys = SystemMessage(\n",
    "        \"You are a concise, factual assistant. Write a brief answer (1–3 sentences) \"\n",
    "        \"directly addressing the subject. Prefer concrete facts and plain language. \"\n",
    "        \"If information is uncertain or missing, say you’re unsure—do not invent details. \"\n",
    "        \"Return only the answer text (no preambles or formatting).\"\n",
    "    )\n",
    "     \n",
    "    # Replace None with the correct variable\n",
    "    user = HumanMessage(None)  \n",
    "    # Replace None with the messages to send into the LLM\n",
    "    draft = llm.invoke([None, None]).content\n",
    "    # Replace None with the variable holding the model output\n",
    "    return {\"draft\": None}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978a375-91e3-454e-88bd-831c91482484",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "# Replace None with the correct variable\n",
    "user = HumanMessage(subject)  \n",
    "\n",
    "# Replace None with the messages to send into the LLM\n",
    "draft = llm.invoke([sys, user]).content  \n",
    "\n",
    "# Replace None with the variable holding the model output\n",
    "return {\"draft\": draft}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ec113-a0fc-4561-8ea4-33d9942e6d2c",
   "metadata": {},
   "source": [
    "The review node triggers a pause with interrupt(...).  \n",
    "LangGraph stops here and returns control to the notebook so we can ask a human to approve or edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "76dc6dda-1b78-4ae2-8e9f-fa61c14d872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- review node (HITL pause) ---\n",
    "def review_node(state: State) -> State:\n",
    "    draft = (state.get(\"draft\") or \"\").strip()\n",
    "    feddback = interrupt({\n",
    "        \"draft\": draft,\n",
    "        \"instructions\": \"Type YES to approve, or provide edits.\"\n",
    "    })\n",
    "\n",
    "    # When the graph is resumed with Command(resume=...), that value is assigned to feddback\n",
    "    return {\"human_feedback\": feddback}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94956c2-6aa1-47b0-9be0-1807aa857964",
   "metadata": {},
   "source": [
    "The finalize node returns the draft as-is if the human typed “YES”.\n",
    "Otherwise, it revises using the human’s edits via the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0e0376c6-980f-4b25-b126-3ff9e14d1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_node(state: State) -> State:\n",
    "    # Normalize inputs and guard against missing keys\n",
    "    subject = (state.get(\"None\") or \"\").strip()\n",
    "    draft   = (state.get(\"None\") or \"\").strip()\n",
    "    fb      = (state.get(\"None\") or \"\").strip()\n",
    "\n",
    "    # Treat empty input or common approvals as \"approve\"\n",
    "    approved = (fb == \"\") or fb.lower().startswith((\"y\", \"yes\"))\n",
    "\n",
    "    if approved:\n",
    "        return {\"final\": draft}\n",
    "\n",
    "    sys = SystemMessage(\n",
    "        \"Revise the draft based on the edits. \"\n",
    "        \"Keep it short (1–3 sentences), clear, and factual. \"\n",
    "        \"Do not make up information. \"\n",
    "        \"Return only the revised answer text.\"\n",
    "    )\n",
    "\n",
    "    # Human message with clear delimiters to separate fields\n",
    "    user = HumanMessage(\n",
    "        \"Please revise the draft using the edits below.\\n\\n\"\n",
    "        f\"Subject:\\n```text\\n{subject}\\n```\\n\\n\"\n",
    "        f\"Draft:\\n```text\\n{draft}\\n```\\n\\n\"\n",
    "        f\"Edits:\\n```text\\n{fb}\\n```\\n\\n\"\n",
    "        \"Revised answer:\"\n",
    "    )\n",
    "\n",
    "    out = llm.invoke([sys, user])\n",
    "    return {\"final\": out.content.strip()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e80f62-0650-49a8-9d36-b7b537b4cf83",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "subject = (state.get(\"subject\") or \"\").strip()\n",
    "draft   = (state.get(\"draft\") or \"\").strip()\n",
    "fb      = (state.get(\"human_feedback\") or \"\").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4dc88707-071d-40a6-963e-86afeb8a7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = StateGraph(State)\n",
    "\n",
    "g.add_node(\"draft\", draft_node)\n",
    "g.add_node(\"review\", review_node)\n",
    "g.add_node(\"finalize\", finalize_node)\n",
    "\n",
    "# --- wire with START/END ---\n",
    "g.add_edge(START, \"draft\")       # entry point\n",
    "g.add_edge(\"draft\", \"review\")\n",
    "g.add_edge(\"review\", \"finalize\")\n",
    "g.add_edge(\"finalize\", END)      # finish point\n",
    "\n",
    "graph = g.compile(checkpointer=MemorySaver())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b5f25fc8-f213-48c8-aee0-40cabcd77661",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"None\"   # <-- your subject here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f5e57-b7d9-4ecf-92b7-39c4778bccc3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "subject = \"how many cats are in israel?\"   # <-- your subject here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c939cc-8a60-43ed-8a88-203bd8839d86",
   "metadata": {},
   "source": [
    "We invoke the graph with a subject.\n",
    "If the output contains __interrupt__, the graph is paused. We display the draft & instructions, collect human feedback , then resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079c278-3443-4e4d-999b-b43c9e2f899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "config = {\"configurable\": {\"thread_id\": f\"hitl-{uuid.uuid4()}\"}}\n",
    "\n",
    "out = graph.invoke({\"subject\": subject}, config=config)\n",
    "\n",
    "if \"__interrupt__\" in out:\n",
    "    print(\">>> PAUSED — waiting for human input\")\n",
    "    intr = out[\"__interrupt__\"][0]\n",
    "    print(\"== REVIEW DRAFT ==\")\n",
    "    print(intr.value[\"draft\"])\n",
    "    print(intr.value[\"instructions\"])\n",
    "\n",
    "    human = input(\"\\nApprove or edit: \")\n",
    "    out = graph.invoke(Command(resume=human), config=config)\n",
    "\n",
    "print(\"\\n== FINAL ANSWER ==\")\n",
    "print(out.get(\"final\", out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13cfaee-96bd-463e-ad57-eecc00baa495",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccabe6eb-c768-46d8-a4c9-71fbe9599741",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cfc3c-f756-47dc-9845-952190fd7ed3",
   "metadata": {},
   "source": [
    "## ⏳ Time Travel in LangGraph\n",
    "\n",
    "LangGraph supports **time travel**, which lets you rewind to a past checkpoint, modify state if needed, and resume execution from there.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Run the graph**  \n",
    "   Start with your initial inputs using `invoke(...)` or `stream(...)`.\n",
    "\n",
    "2. **Locate a checkpoint**  \n",
    "   - Use `get_state_history(thread_id)` to list execution history and find the desired `checkpoint_id`.  \n",
    "   - Or, set an `interrupt(...)` before a node where you want execution to pause; you can then use the latest checkpoint created up to that point.\n",
    "\n",
    "3. **(Optional) Update state**  \n",
    "   Modify the graph’s state at that checkpoint using `update_state(...)`.\n",
    "\n",
    "4. **Resume from checkpoint**  \n",
    "   Call `invoke(None, config={...})` or `stream(None, config={...})` with the correct `thread_id` and `checkpoint_id` to continue execution from that point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cb05aea9-79ae-4ece-a101-81a4bc1b2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver \n",
    "\n",
    "class State(TypedDict, total=False):\n",
    "    topic: str\n",
    "    joke: str\n",
    "\n",
    "def generate_topic(state: State) -> State:\n",
    "    sys = SystemMessage(\n",
    "        \"You generate short, concrete topics for jokes. Each time, pick a DIFFERENT subject. \"\n",
    "        \"Vary widely across animals, objects, events, or everyday things. \"\n",
    "        \"Respond with only one or two words.\"\n",
    "    )\n",
    "    user = HumanMessage(\"Pick a random topic for a joke. Be creative and change it every time.\")\n",
    "    return {\"topic\": llm.invoke([sys, user]).content.strip()}\n",
    "\n",
    "def write_joke(state: State) -> State:\n",
    "    # Replace None with a suitable system prompt \n",
    "    sys = SystemMessage(\"None\")\n",
    "    user = HumanMessage(f\"Topic: {state['topic']}\")\n",
    "    return {\"joke\": llm.invoke([sys, user]).content.strip()}\n",
    "\n",
    "# Build\n",
    "g = StateGraph(State)\n",
    "\n",
    "g.add_node(\"generate_topic\", generate_topic)\n",
    "g.add_node(\"write_joke\", write_joke)\n",
    "g.add_edge(START, \"generate_topic\")\n",
    "g.add_edge(\"generate_topic\", \"write_joke\")\n",
    "g.add_edge(\"write_joke\", END)\n",
    "\n",
    "graph = g.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b675ea-2062-40ff-90de-357039f0d9e5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "sys = SystemMessage(\n",
    "    \"You are a stand-up comedian performing for a mixed audience. \"\n",
    "    \"Always write a short, clever joke about the given topic. \"\n",
    "    \"Avoid offensive content.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5ed38-ee8a-4416-9268-3669479cf17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) First run\n",
    "import uuid\n",
    "config = {\"configurable\": {\"thread_id\": f\"hitl-{uuid.uuid4()}\"}}\n",
    "state1 = graph.invoke({}, config)\n",
    "print(\"First topic:\", state1[\"topic\"])\n",
    "print(\"First joke:\", state1[\"joke\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce18a8-211b-43c1-a3ea-b1b7110345eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Inspect history and pick the checkpoint right before write_joke\n",
    "states = list(graph.get_state_history(config))  # newest first\n",
    "snap_before_write = next(s for s in states if \"write_joke\" in s.next)\n",
    "print(\"Resuming from checkpoint:\", snap_before_write.config[\"configurable\"][\"checkpoint_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c4cab056-9594-471c-ae26-9dbba6e44b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Time-travel: change the topic at that checkpoint (branch state)\n",
    "topic = \"None\" # <--- insert a topic \n",
    "new_config = graph.update_state(snap_before_write.config, values={\"topic\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91fcae-98c5-42c2-af5c-7e75e651baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Resume from that checkpoint; only write_joke runs again\n",
    "state2 = graph.invoke({}, new_config)\n",
    "print(\"Branched topic:\", state2[\"topic\"])\n",
    "print(\"Branched joke:\", state2[\"joke\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e54956a-1b4a-43fe-9ba7-932720843b94",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512c9ce-95fb-4d66-a818-4c9aceb4bee9",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda32d6f-9d00-4e05-a0b7-c9737420d908",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9436115-2ad5-4398-bc28-a7cbf16ab092",
   "metadata": {},
   "source": [
    "#### 🤖 ChatBot\n",
    "\n",
    "In this section, we’ll start building a chatbot step by step:\n",
    "\n",
    "1. **Basic Chatbot** – The chatbot will first communicate directly with the LLM, responding to user input in a simple conversation loop.  \n",
    "2. **Agentic Chatbot with Tools** – Next, we’ll enrich the chatbot by giving it access to external tools.  \n",
    "   This effectively turns it into an *agent* that can decide when to call a tool (e.g., web search, image generation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "357434ef-94df-40ee-a28d-cbb7845616a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning)\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from openai import AzureOpenAI\n",
    "from langchain_tavily import TavilySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "810eb7b5-c86f-4c71-b96b-749ad9aa255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # merges state by appending new messages instead of overwriting the list.\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a518b-0fb9-4512-b67f-27a788121654",
   "metadata": {},
   "source": [
    "Lets define the chatbot node, which takes user prompt (with the history),\n",
    "sends it to the LLM, and returns the assistant’s reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "45bcd2d4-9d1b-4f84-89bc-74b8a58e34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    msgs = state[\"messages\"]\n",
    "    return {\"messages\": [llm.invoke(msgs)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "88a6e178-3929-42d0-89c4-e40ff32ce26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8e61a9f3-9785-468f-b5ab-caeeb37a0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "def get_content(msg):\n",
    "    return msg.content if isinstance(msg, BaseMessage) else msg.get(\"content\", \"\")\n",
    "\n",
    "# An interactive session that takes user input, sends it to the graph, \n",
    "# streams back the assistant’s latest message from the output, and prints it to the terminal.\n",
    "def run_chat_loop(app):\n",
    "    print(\"Type 'quit' to exit.\\n\")\n",
    "    config = {\"configurable\": {\"thread_id\": f\"hitl-{uuid.uuid4()}\"}}\n",
    "\n",
    "    while True:\n",
    "        user = input(\"User: \")\n",
    "        if user.strip().lower() in {\"quit\", \"exit\", \"q\"}:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Send ONLY the new HumanMessage; the rest of the history is in the checkpoint\n",
    "        result = app.invoke({\"messages\": [HumanMessage(content=user)]}, config=config)\n",
    "\n",
    "        # The latest assistant message is the last in state[\"messages\"]\n",
    "        last = result[\"messages\"][-1]\n",
    "        print(\"Assistant:\", last.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907acdb-d701-4166-89a6-6f67d9bdc744",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_chat_loop(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca46cf8-0a4a-4e06-8856-6fad1412db77",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf469c91-21e3-4991-9b69-a96ff7603d4f",
   "metadata": {},
   "source": [
    "Now lets upgrade the simple LLM chatbot into an agent that can call tools. one for fresh web search and one for image generation.  \n",
    "so it can pull up-to-date info and create images on demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de37da92-a5fd-467b-9f85-d4b6c0c94c4b",
   "metadata": {},
   "source": [
    "Lets make the create image we declared before into a tool our chatbot agent could use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1476c3bf-2d5a-4d5c-9848-3d974ea3574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tells the agent it must provide a prompt string\n",
    "class CreateImageInput(BaseModel):\n",
    "    prompt: str = Field(..., description=\"Text describing the image to generate.\")\n",
    "\n",
    "# '@tool' registers the function so the agent can call it when an image request is detected.\n",
    "@tool(\"create_image_tool\", args_schema=None)\n",
    "def create_image_tool(prompt: str) -> str:\n",
    "    \"\"\"Generate an image using Azure OpenAI Images (DALL·E) and return a URL.\"\"\"\n",
    "    try:\n",
    "        return create_image(prompt)\n",
    "    except Exception as e:\n",
    "        return f\"Image generation failed: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55d01b-1251-44cb-aadc-cc092d8c94b3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "@tool(\"create_image\", args_schema=CreateImageInput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe0d00f-a8ff-4ae4-8880-b3d699d07a60",
   "metadata": {},
   "source": [
    "Let’s add a search tool so the agent can perform real-time web lookups.\n",
    "We’ll use TavilySearch, a LangChain community tool that wraps the Tavily API for seamless, up-to-date results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6dd917fd-7c0d-4969-8948-3295e0039d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearch(tavily_api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0032670c-b461-44fc-87f5-18838be82af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the tools you want the agent to have\n",
    "tools = [None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92afe63b-9dd4-4566-8b6c-b65efe7e2226",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Answer key (click to expand)</b></summary>\n",
    "\n",
    "```python\n",
    "# list of all the tools you want the agent to have\n",
    "tools = [search_tool, create_image_tool]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef94350d-e24b-420f-a7d2-b74cf82783dd",
   "metadata": {},
   "source": [
    "Lets create the chatbot agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bd2b3161-6727-4c6d-baa4-501cf17867fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the agent’s prompt\n",
    "chatbot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful AI assistant. \"\n",
    "     \"Use search tool for fresh/accurate web info. \"\n",
    "     \"When the user asks to generate/draw/design an image, call the `create_image` tool. \"\n",
    "     \"Be concise and factual. Do not dump raw search results.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# Create the agent and wrap it in an AgentExecutor that handles tool calls and returns the final output.\n",
    "chatbot_agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=chatbot_prompt)\n",
    "chatbot_executor = AgentExecutor(agent=chatbot_agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "85d9ee8e-a962-4f1c-b161-2f3333e4f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(msg):\n",
    "    return msg.content if isinstance(msg, BaseMessage) else msg.get(\"content\", \"\")\n",
    "\n",
    "def chatbot_node(state: State):\n",
    "    last = state[\"messages\"][-1]\n",
    "    query = get_content(last)\n",
    "\n",
    "    history = state[\"messages\"][:-1]\n",
    "    result = chatbot_executor.invoke({\n",
    "        \"input\": query,\n",
    "        \"chat_history\": history,  \n",
    "    })\n",
    "\n",
    "    # Let the reducer append; return ONLY the new message\n",
    "    return {\"messages\": [AIMessage(content=result[\"output\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c071c5-3172-4006-be2b-400f5f99d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf0c3f-dc0f-4f90-8e3d-26b189bc5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_chat_loop(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4839999-e171-4bb6-8171-7e3d345cad92",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e2281-bdfc-4a3e-abbc-055caac6f40a",
   "metadata": {},
   "source": [
    "## 🎙️ Podcast Generator Agent\n",
    "\n",
    "In this section, we are going to build a LangGraph-powered multi-step agentic workflow that automatically generates and produces a podcast episode end-to-end.\n",
    "\n",
    "🔑 What it does\n",
    "\n",
    "- Starts from a user-provided topic.\n",
    "\n",
    "- Creates a high-level outline of the podcast.\n",
    "\n",
    "- Iteratively performs research using multiple tools (Wikipedia, Tavily).\n",
    "\n",
    "- Writes a draft podcast script, citing credible sources.\n",
    "\n",
    "- Runs a critique + revision loop to refine the script.\n",
    "\n",
    "- Converts the final script into speech with Azure TTS, alternating between two voices.\n",
    "\n",
    "- Merges audio files into a complete MP3 podcast episode."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa3ec97b-b33d-40c6-b36c-6990c8bab1bf",
   "metadata": {},
   "source": [
    "![Conditional Graph](https://raw.githubusercontent.com/eliranabre/AgentsWorkshp_HEaD/main/podcast.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4f7b0ba-b83a-4b77-8e5f-61079bcf52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the topic for your podcast\n",
    "PODCAST_TOPIC = \"None\"  # <---------- choose a topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f9efc98-0ee6-4c58-bb96-c5b651ab1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "import subprocess\n",
    "import imageio_ffmpeg\n",
    "from typing import TypedDict\n",
    "\n",
    "from IPython.display import Audio, display, Markdown\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema.document import Document\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "\n",
    "# ========================== Memory ==========================\n",
    "memory = MemorySaver()\n",
    "\n",
    "# ========================== State ==========================\n",
    "class AgentState(TypedDict):\n",
    "    revision_number: int\n",
    "    max_revisions: int\n",
    "    search_count: int\n",
    "    max_searches: int\n",
    "    task: str\n",
    "    outline: str\n",
    "    queries: list\n",
    "    content: list\n",
    "    draft: str\n",
    "    critique: str\n",
    "    tool_calls: list\n",
    "    parsed_script: list\n",
    "    audio_parts: list\n",
    "    audio_path: str\n",
    "\n",
    "# ========================== Tools ==========================\n",
    "search_tool = TavilySearch(tavily_api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "\n",
    "@tool\n",
    "def search_online(query: str) -> list[Document]:\n",
    "    \"\"\"Search for information online using Tavily.\"\"\"\n",
    "    docs = search_tool.invoke(query)\n",
    "    return docs or [\"No results found online\"]\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> list[Document]:\n",
    "    \"\"\"Search for information on Wikipedia.\"\"\"\n",
    "    retriever = WikipediaRetriever()\n",
    "    docs = retriever.invoke(query)\n",
    "    return docs or [\"No results found on Wikipedia\"]\n",
    "\n",
    "RESEARCH_TOOLS = [search_online, search_wikipedia]\n",
    "\n",
    "# ========================== Prompts ==========================\n",
    "OUTLINE_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an engaging 2-minute podcast.\n",
    "Write such an outline for the user provided topic. Give an outline of the podcast along with any\n",
    "relevant notes or instructions for the sections.\"\"\"\n",
    "\n",
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher tasked with providing information that can\n",
    "be used when writing the following podcast. Generate one search query consisting of a few\n",
    "keywords that will be used to gather any relevant information. Do not output any information\n",
    "other than the query consisting of a few words.\n",
    "\n",
    "These were the past queries, do not repeat keywords from past queries in your newly generated query:\n",
    "---\n",
    "{queries}\"\"\"\n",
    "\n",
    "WRITER_PROMPT = \"\"\"\n",
    "You are a writing assistant tasked with writing engaging 2-minute podcast scripts.\n",
    "\n",
    "- Generate the best podcast script possible for the user's request and the initial outline.\n",
    "- The script MUST strictly alternate lines between the two hosts, separating each host's line with a newline.\n",
    "- Add an intro phrase and outro phrase to start and end the podcast, and use a fun, random name for the podcast show.\n",
    "- Given a critique, respond with a revised version of your previous script.\n",
    "- Include lively back-and-forth chatter, reflections, and expressions of amazement between the hosts.\n",
    "- Cite at least THREE pieces of research throughout the script, choosing the most relevant research for each point.\n",
    "- DO NOT include ANY of the following:\n",
    "    - Speaker labels (e.g., \"Host 1:\", \"Host 2:\")\n",
    "    - Sound effect descriptions (e.g., \"[Sound of waves]\")\n",
    "    - Formatting instructions (e.g., \"(Emphasis)\", \"[Music fades in]\")\n",
    "    - Any other non-dialogue text.\n",
    "- Use this format for citations, including the month and year if available:\n",
    "    \"In [Month, Year], [Organization] found that...\"\n",
    "    \"Research from [Organization] in [Month, Year] showed that...\"\n",
    "    \"Back in [Month, Year], a study by [Organization] suggested that...\"\n",
    "---\n",
    "Utilize all of the following search results and context as needed:\n",
    "{content}\n",
    "---\n",
    "If this is a revision, the critique will be provided below:\n",
    "{critique}\"\"\"\n",
    "\n",
    "CRITIQUE_PROMPT = \"\"\"You are a producer grading a podcast script.\n",
    "Generate critique and recommendations for the user's submission.\n",
    "Provide detailed recommendations, including requests for conciseness, depth, style, etc.\"\"\"\n",
    "\n",
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a writing assistant tasked with providing information that can\n",
    "be used when making any requested revisions (as outlined below).\n",
    "Generate one search query consisting of a few keywords that will be used to gather any relevant\n",
    "information. Do not output any information other than the query consisting of a few words.\n",
    "\n",
    "These were the past queries, so you can vary the query that you generate:\n",
    "---\n",
    "{queries}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "RESEARCH_AGENT_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a focused research assistant. Given a topic or search query, \"\n",
    "     \"pick the best tool(s), gather a few high-quality sources, and produce a concise evidence summary. \"\n",
    "     \"Prefer diverse sources. If one tool fails, try another. Stop when you have enough.\"),\n",
    "    (\"user\", \"{query}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "\n",
    "research_agent = create_tool_calling_agent(\n",
    "    llm=llm,\n",
    "    tools=RESEARCH_TOOLS,\n",
    "    prompt=RESEARCH_AGENT_PROMPT,\n",
    ")\n",
    "\n",
    "research_executor = AgentExecutor(\n",
    "    agent=research_agent,\n",
    "    tools=RESEARCH_TOOLS,\n",
    "    verbose=False,         # set True if you want to see tool traces\n",
    "    max_iterations=3,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "# ========================== Nodes ==========================\n",
    "def podcast_outline_node(state: AgentState):\n",
    "    messages = [SystemMessage(content=OUTLINE_PROMPT), HumanMessage(content=state[\"task\"])]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"outline\": response.content}\n",
    "\n",
    "def research_plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT.format(queries=state.get(\"queries\", []))),\n",
    "        HumanMessage(content=state[\"task\"]),\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    prev = state.get(\"queries\", [])\n",
    "    return {\"queries\": prev + [response.content]}\n",
    "\n",
    "def research_agent_node(state: AgentState):\n",
    "    # Use the latest planned query\n",
    "    query = (state.get(\"queries\") or [\"\"])[-1]\n",
    "\n",
    "    # Run the agent loop (model ↔ tools ↔ observations)\n",
    "    result = research_executor.invoke({\"query\": query})\n",
    "    final_summary = result[\"output\"]\n",
    "    steps = result.get(\"intermediate_steps\", [])  # [(AgentAction, observation), ...]\n",
    "\n",
    "    # Keep newest content first\n",
    "    new_content = [final_summary] + (state.get(\"content\") or [])\n",
    "\n",
    "    # Lightweight log of tool calls (optional)\n",
    "    tool_log = state.get(\"tool_calls\") or []\n",
    "    for action, observation in steps:\n",
    "        tool_log.append({\n",
    "            \"tool\": getattr(action, \"tool\", \"\"),\n",
    "            \"input\": getattr(action, \"tool_input\", \"\"),\n",
    "            \"observation\": str(observation)[:800],\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"content\": new_content,\n",
    "        \"tool_calls\": tool_log,\n",
    "        \"search_count\": state[\"search_count\"] + 1,\n",
    "    }\n",
    "\n",
    "def should_continue_tools(state: AgentState):\n",
    "    # Continue planning/research until search_count > max_searches\n",
    "    return \"generate_script\" if state[\"search_count\"] > state[\"max_searches\"] else \"research_plan\"\n",
    "\n",
    "def generate_script_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=WRITER_PROMPT.format(\n",
    "            content=state[\"content\"],\n",
    "            critique=state.get(\"critique\", \"\")\n",
    "        )),\n",
    "        HumanMessage(content=f\"{state['task']}\\n\\nHere is my outline:\\n\\n{state['outline']}\"),\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content,\n",
    "        \"search_count\": 0,\n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n",
    "\n",
    "def perform_critique_node(state: AgentState):\n",
    "    messages = [SystemMessage(content=CRITIQUE_PROMPT), HumanMessage(content=state[\"draft\"])]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"critique\": response.content}\n",
    "\n",
    "def research_critique_node(state: AgentState):\n",
    "    # Keep the original approach: produce another query from the critique\n",
    "    messages = [\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT.format(queries=state.get(\"queries\", []))),\n",
    "        HumanMessage(content=state[\"critique\"]),\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    prev = state.get(\"queries\", [])\n",
    "    return {\"queries\": prev + [response.content]}\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    # When revisions exceed max_revisions, proceed to TTS\n",
    "    return \"parse_script\" if state[\"revision_number\"] > state[\"max_revisions\"] else \"perform_critique\"\n",
    "\n",
    "def parse_script_node(state: AgentState):\n",
    "    draft = state.get(\"draft\", \"\")\n",
    "    return {\"parsed_script\": to_lines(draft) if draft else []}\n",
    "\n",
    "def tts_synthesize_node(state: AgentState):\n",
    "    # Azure TTS (needs AZURE_TTS_KEY and AZURE_TTS_REGION)\n",
    "    speech_config = speechsdk.SpeechConfig(\n",
    "        subscription=os.environ[\"AZURE_TTS_KEY\"],\n",
    "        region=os.environ[\"AZURE_TTS_REGION\"]\n",
    "    )\n",
    "    voice_options = [\"en-US-AriaNeural\", \"en-US-GuyNeural\"]\n",
    "\n",
    "    os.makedirs(\"tts_parts\", exist_ok=True)\n",
    "    audio_files = []\n",
    "\n",
    "    parsed = state.get(\"parsed_script\", []) or []\n",
    "    for idx, line in enumerate(parsed):\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        speech_config.speech_synthesis_voice_name = voice_options[idx % 2]\n",
    "        filename = f\"tts_parts/part-{idx}.wav\"\n",
    "        audio_config = speechsdk.audio.AudioOutputConfig(filename=filename)\n",
    "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "        result = synthesizer.speak_text_async(line).get()\n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            audio_files.append(filename)\n",
    "\n",
    "    return {\"audio_parts\": audio_files}\n",
    "\n",
    "def merge_audio_node(state: AgentState):\n",
    "    parts = state.get(\"audio_parts\", []) or []\n",
    "    if not parts:\n",
    "        return {\"audio_path\": \"\"}\n",
    "\n",
    "    ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "    if not ffmpeg_exe:\n",
    "        raise RuntimeError(\"Could not find or install ffmpeg\")\n",
    "\n",
    "    filelist_path = \"tts_parts/filelist.txt\"\n",
    "    with open(filelist_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for p in parts:\n",
    "            abs_path = os.path.abspath(p).replace(\"\\\\\", \"/\")\n",
    "            f.write(f\"file '{abs_path}'\\n\")\n",
    "\n",
    "    output_path = \"azure-podcast.mp3\"\n",
    "    cmd = [\n",
    "        ffmpeg_exe, \"-y\",\n",
    "        \"-f\", \"concat\", \"-safe\", \"0\",\n",
    "        \"-i\", filelist_path,\n",
    "        \"-c:a\", \"libmp3lame\", \"-b:a\", \"192k\",\n",
    "        output_path\n",
    "    ]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    # best-effort cleanup\n",
    "    try:\n",
    "        for p in parts:\n",
    "            try:\n",
    "                os.remove(p)\n",
    "            except PermissionError:\n",
    "                time.sleep(0.5)\n",
    "                try:\n",
    "                    os.remove(p)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        os.remove(filelist_path)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        return {\"audio_path\": f\"ffmpeg failed: {result.stderr[:300]}\"}\n",
    "\n",
    "    return {\"audio_path\": output_path}\n",
    "\n",
    "# ========================== Helpers ==========================\n",
    "def clean_agent_result(data):\n",
    "    s = str(data)\n",
    "    s = re.sub(r\"[^\\x00-\\x7F]+\", \" \", s)\n",
    "    s = re.sub(r\"\\\\\\\\n\", \"\\n\", s)\n",
    "    s = re.sub(r\"\\\\n\", \"\", s)\n",
    "    s = re.sub(r\"\\\\'\", \"'\", s)\n",
    "    return s\n",
    "\n",
    "def to_lines(draft: str):\n",
    "    lines = [ln.strip() for ln in draft.replace(\"\\r\\n\", \"\\n\").split(\"\\n\") if ln.strip()]\n",
    "    lines = [re.sub(r'^[\\-\\*\\u2022\\d\\.\\)\\s]+', '', ln) for ln in lines]\n",
    "    return lines\n",
    "\n",
    "# ========================== Graph ==========================\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"podcast_outline\", podcast_outline_node)\n",
    "workflow.add_node(\"research_plan\", research_plan_node)\n",
    "workflow.add_node(\"research_agent\", research_agent_node)\n",
    "workflow.add_node(\"generate_script\", generate_script_node)\n",
    "workflow.add_node(\"perform_critique\", perform_critique_node)\n",
    "workflow.add_node(\"research_critique\", research_critique_node)\n",
    "workflow.add_node(\"parse_script\", parse_script_node)\n",
    "workflow.add_node(\"tts_synthesize\", tts_synthesize_node)\n",
    "workflow.add_node(\"merge_audio\", merge_audio_node)\n",
    "\n",
    "workflow.set_entry_point(\"podcast_outline\")\n",
    "\n",
    "# fixed edges\n",
    "workflow.add_edge(\"podcast_outline\", \"research_plan\")\n",
    "workflow.add_edge(\"research_plan\", \"research_agent\")\n",
    "workflow.add_edge(\"perform_critique\", \"research_critique\")\n",
    "workflow.add_edge(\"research_critique\", \"research_agent\")\n",
    "\n",
    "# conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"research_agent\",\n",
    "    should_continue_tools,\n",
    "    {\"generate_script\": \"generate_script\", \"research_plan\": \"research_plan\"},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_script\",\n",
    "    should_continue,\n",
    "    {\"perform_critique\": \"perform_critique\", \"parse_script\": \"parse_script\"},\n",
    ")\n",
    "\n",
    "# TTS path\n",
    "workflow.add_edge(\"parse_script\", \"tts_synthesize\")\n",
    "workflow.add_edge(\"tts_synthesize\", \"merge_audio\")\n",
    "workflow.add_edge(\"merge_audio\", END)\n",
    "\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e01e5-5051-4b4a-bdf7-b43d3f0c5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": f\"hitl-{uuid.uuid4()}\"}}\n",
    "\n",
    "initial_state = {\n",
    "    \"task\": PODCAST_TOPIC,\n",
    "    \"revision_number\": 1,\n",
    "    \"max_revisions\": 2,\n",
    "    \"search_count\": 0,\n",
    "    \"max_searches\": 1,\n",
    "    \"content\": [],\n",
    "    \"queries\": [],\n",
    "    \"tool_calls\": [],\n",
    "    \"parsed_script\": [],\n",
    "    \"audio_parts\": [],\n",
    "    \"audio_path\": \"\",\n",
    "}\n",
    "\n",
    "for state in graph.stream(initial_state, config):\n",
    "    for k, v in state.items():\n",
    "        print(f\"Agent Node: {k}\\n\")\n",
    "        # show a human-friendly snippet\n",
    "        display(Markdown(clean_agent_result(v)[:1000]))\n",
    "\n",
    "        # auto-play when we hit the merged MP3\n",
    "        if k == \"merge_audio\":\n",
    "            if isinstance(v, dict) and v.get(\"audio_path\", \"\").endswith(\".mp3\"):\n",
    "                display(Audio(v[\"audio_path\"]))\n",
    "    print(\"\\n====================\\n\")\n",
    "# =============================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
